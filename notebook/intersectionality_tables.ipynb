{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ReadMe\n",
        "## Summary\n",
        "- notebook for some figures\n",
        "\n",
        "## Prerequisite\n",
        "- Run repo's `notebook/vilio_gradient.ipynb` to obtain vilio results and intermediate files\n",
        "- place LLama-2 result as `DRIVE_DIR/LLM_PATH`\n"
      ],
      "metadata": {
        "id": "nP0JHwH9EP5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# init"
      ],
      "metadata": {
        "id": "oS5VbqtcEpbg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## env"
      ],
      "metadata": {
        "id": "9jqd70GjSdKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna==3.3.0"
      ],
      "metadata": {
        "id": "KbLxvx77SjK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## modules and variables"
      ],
      "metadata": {
        "id": "opAEP7yME5q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "import glob\n",
        "import os\n",
        "from typing import List\n",
        "import warnings\n",
        "\n",
        "import dask.dataframe as dd\n",
        "from dask import delayed\n",
        "# import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import optuna.integration.lightgbm as opt_lgb\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "# from sklearn.decomposition import PCA\n",
        "# from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "%matplotlib inline\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "metadata": {
        "id": "7Z0A-cudJ_xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/drive/MyDrive/vilio/export/V/attattr\n",
        "DRIVE_DIR=\"/content/drive/MyDrive\"\n",
        "LLM_PATH=\"hf/meta_result.csv\"\n",
        "VILIO_DIR=\"vilio/export\"\n",
        "VILIO_MODELS=[\"O\",\"U\",\"V\"]\n",
        "SCORE_TYPE=\"attattr\"\n",
        "SUBMODELS={\n",
        "    \"O\": [\"O36\",\"O50\",\"OV50\"],\n",
        "    \"U\": [\"U36\",\"U50\",\"U72\"],\n",
        "    \"V\": [\"V135\",\"V45\",\"V90\"],\n",
        "}\n",
        "INPUT_MODALITIES=[\"img\",\"txt\"]\n",
        "INTERACTION_MODALITIES=[\"cross\",\"image\",\"text\"]\n",
        "EXPORT_DIR=\"additional_figures\"\n",
        "SPLIT=\"dev_seen\"\n",
        "RS=1991"
      ],
      "metadata": {
        "id": "mS-Z6c6iE8Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ATTR_COL=\"score\"\n",
        "PRED_COL=\"micace\"\n",
        "plot_cols={ATTR_COL: \"MIDAS\", PRED_COL: \"miATE\"}\n",
        "\n",
        "KEEP_COLS=[\"id\",\"input_modality\",\"model_type\",\"submodel\",\"micace\",\"score\"]\n",
        "KEY_COLS=[\"id\",\"input_modality\",\"model_type\",\"submodel\"]\n",
        "\n",
        "dummy_cols = deepcopy(KEY_COLS)\n",
        "dummy_cols.remove(\"id\")"
      ],
      "metadata": {
        "id": "k3L9gFHjC8Dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(f\"{DRIVE_DIR}/{VILIO_DIR}/{EXPORT_DIR}\", exist_ok=True)"
      ],
      "metadata": {
        "id": "sbwGRTcg-Iee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## functions"
      ],
      "metadata": {
        "id": "xH3VG6v-LoWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_lgb_results(drive_dir=DRIVE_DIR,vilio_dir=VILIO_DIR,export_dir=EXPORT_DIR,score_type=SCORE_TYPE,search_str=\"\"):\n",
        "    results = glob.glob(f\"{drive_dir}/{vilio_dir}/{export_dir}/*{search_str}*.csv\")\n",
        "    return results\n",
        "\n",
        "@delayed\n",
        "def read_csv_w_meta(file_path: str):\n",
        "    df = pd.read_csv(file_path)\n",
        "    cols = df.columns.tolist()\n",
        "    filename_seg = file_path.split(\"/\")[-1].split(\"_\")\n",
        "    df[\"model_type\"], df[\"seed\"] = filename_seg[0], filename_seg[-1].split(\".\")[0]\n",
        "    return df[[\"model_type\",\"seed\"]+cols]\n",
        "\n",
        "def read_csvs_w_meta(file_list: List[str],):\n",
        "    ddf = dd.from_delayed(\n",
        "        [read_csv_w_meta(file_path) for file_path in file_list]\n",
        "    )\n",
        "    df = ddf.compute()\n",
        "    return df\n",
        "\n",
        "def lgb_results2df(search_strs = [\"_indv_optuna_occurrences_\",\"_indv_optuna_nunique_\"]):\n",
        "    dfs = {s: None for s in search_strs}\n",
        "    for search_str in search_strs:\n",
        "        file_list = collect_lgb_results(search_str=search_str)\n",
        "        df = read_csvs_w_meta(file_list)\n",
        "        dfs[search_str] = df.copy()\n",
        "    return dfs\n",
        "\n",
        "def collect_vilio_results(drive_dir=DRIVE_DIR,vilio_dir=VILIO_DIR,score_type=SCORE_TYPE,split=SPLIT):\n",
        "    results = glob.glob(f\"{drive_dir}/{vilio_dir}/*/{score_type}/*{split}_result_*.csv\")\n",
        "    return results\n",
        "\n",
        "@delayed\n",
        "def read_csv_w_source(file_path: str):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df[\"model_type\"], df[\"score_type\"], file_name = file_path.split(\"/\")[-3:]\n",
        "    df[\"input_modality\"], df[\"submodel\"] = file_name.split(\"_\")[:2]\n",
        "    df[\"interaction_type\"] = file_name.split(\"_\")[-1].split(\".\")[0]\n",
        "    return df.drop_duplicates()\n",
        "\n",
        "def read_csvs_w_source(file_list: List[str]):\n",
        "    ddf = dd.from_delayed(\n",
        "        [read_csv_w_source(file_path) for file_path in file_list]\n",
        "    )\n",
        "    df = ddf.compute()\n",
        "    return df\n",
        "\n",
        "def vilio_results2df():\n",
        "    file_list = collect_vilio_results()\n",
        "    df = read_csvs_w_source(file_list)\n",
        "    return df\n",
        "\n",
        "def ate_score(y_true: np.array, y_pred: np.array):\n",
        "    score_pos = y_pred[y_true==1].sum()/len(y_pred[y_true==1])\n",
        "    score_neg = y_pred[y_true==0].sum()/len(y_pred[y_true==0])\n",
        "    return score_pos-score_neg\n",
        "\n",
        "def convert_metric_to_method(metric: str):\n",
        "    if metric==\"ate\":\n",
        "        out = ate_score\n",
        "    elif metric==\"acc\":\n",
        "        out = accuracy_score\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    return out\n",
        "\n",
        "def score_over_segment(df: pd.DataFrame, gt_col: str, pred_col: str, segment_col: str, metric: str=\"ate\"):\n",
        "    y_true,y_pred,segment = df[gt_col].values,df[pred_col].values,df[segment_col].values\n",
        "    out, out_col = [], [segment_col, \"cnt\", metric]\n",
        "    for s in sorted(np.unique(segment)):\n",
        "        cnt = len(y_true[segment==s])\n",
        "        calculate_score = convert_metric_to_method(metric)\n",
        "        score = calculate_score(y_true[segment==s], y_pred[segment==s])\n",
        "        out.append([s, cnt, score])\n",
        "    out_df = pd.DataFrame(out, columns=out_col)\n",
        "    return out_df"
      ],
      "metadata": {
        "id": "pcXy-PEaEyfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load data"
      ],
      "metadata": {
        "id": "BDYjTMrPErCh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDcdP8FUymSy"
      },
      "outputs": [],
      "source": [
        "# mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vilio result\n",
        "df_vilio = vilio_results2df()\n",
        "df_vilio.head()"
      ],
      "metadata": {
        "id": "ut7lDFcgL_vZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm result\n",
        "df_llm = pd.read_csv(f\"{DRIVE_DIR}/{LLM_PATH}\")\n",
        "df_llm.head()"
      ],
      "metadata": {
        "id": "3lHsRD_IN06U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analysis"
      ],
      "metadata": {
        "id": "YmoelbRZy5P_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## llm"
      ],
      "metadata": {
        "id": "SVVxx-U5y7qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(seed=RS)\n",
        "df_llm[\"random_label\"] = np.random.randint(2, size=len(df_llm))"
      ],
      "metadata": {
        "id": "YdujBD97gtp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_llm[\"is_hateful_or_sarcastic\"] = (np.logical_or(df_llm[\"is_hateful\"], df_llm[\"is_sarcastic\"])).astype(int)\n",
        "df_llm[\"is_few_shot\"] = 0\n",
        "df_llm.loc[df_llm[\"few_shot_num\"] != 0, \"is_few_shot\"] = 1"
      ],
      "metadata": {
        "id": "L3D-Fss5mVbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_llm[\"is_few_shot\"] = 0\n",
        "df_llm.loc[df_llm[\"few_shot_num\"] != 0, \"is_few_shot\"] = 1"
      ],
      "metadata": {
        "id": "LxPYGkbVNAzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label TTC-absent sample as incorrect\n",
        "df_llm[\"gt_flipped\"] = df_llm[\"ground_truth\"].apply(lambda x: int(not x))\n",
        "df_llm.loc[df_llm[\"is_functional\"]==0, [\"is_functional\", \"ground_truth\", \"is_hateful\"]].value_counts()"
      ],
      "metadata": {
        "id": "XO100uctt1TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use flipped gt label in case of non-functional response\n",
        "df_llm[\"is_hateful_ttc\"] = df_llm[\"is_hateful\"].copy()\n",
        "df_llm.loc[df_llm[\"is_functional\"]==0, \"is_hateful_ttc\"] = df_llm.loc[df_llm[\"is_functional\"]==0, \"gt_flipped\"]\n",
        "df_llm.loc[df_llm[\"is_functional\"]==0, [\"is_functional\", \"ground_truth\", \"is_hateful\", \"is_hateful_ttc\"]].value_counts()\n"
      ],
      "metadata": {
        "id": "Hb7e2F4qz6h-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use flipped gt label in case of non-functional response\n",
        "df_llm[\"is_hateful_or_sarcastic_ttc\"] = df_llm[\"is_hateful_or_sarcastic\"].copy()\n",
        "df_llm.loc[df_llm[\"is_functional\"]==0, \"is_hateful_or_sarcastic_ttc\"] = df_llm.loc[df_llm[\"is_functional\"]==0, \"gt_flipped\"]\n",
        "df_llm.loc[df_llm[\"is_functional\"]==0, [\"is_functional\", \"ground_truth\", \"is_hateful_or_sarcastic\", \"is_hateful_or_sarcastic_ttc\"]].value_counts()"
      ],
      "metadata": {
        "id": "NaMPTW6Zmwmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_llm_ttc = df_llm[df_llm[\"is_functional\"]==1].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "fiqWBNgyd1SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# before flipping\n",
        "for metric in [\"acc\",\"ate\"]:\n",
        "    print(metric)\n",
        "    print(\"all result\")\n",
        "    print(\"random\")\n",
        "    print(score_over_segment(df_llm, \"ground_truth\", \"random_label\", \"few_shot_num\", metric=metric))\n",
        "    print(\"model\")\n",
        "    print(score_over_segment(df_llm, \"ground_truth\", \"is_hateful\", \"few_shot_num\", metric=metric))\n",
        "    print(\"---------------------------------------\")\n",
        "    print(\"ttc\")\n",
        "    print(\"random\")\n",
        "    print(score_over_segment(df_llm_ttc, \"ground_truth\", \"random_label\", \"few_shot_num\", metric=metric))\n",
        "    print(\"model\")\n",
        "    print(score_over_segment(df_llm_ttc, \"ground_truth\", \"is_hateful\", \"few_shot_num\", metric=metric))\n",
        "    print(\"=======================================\")"
      ],
      "metadata": {
        "id": "FGC8rv-x1SBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# before flipping - few_shot or not\n",
        "for metric in [\"acc\",\"ate\"]:\n",
        "    print(metric)\n",
        "    print(\"all result\")\n",
        "    print(\"random\")\n",
        "    print(score_over_segment(df_llm, \"ground_truth\", \"random_label\", \"is_few_shot\", metric=metric))\n",
        "    print(\"model\")\n",
        "    print(score_over_segment(df_llm, \"ground_truth\", \"is_hateful\", \"is_few_shot\", metric=metric))\n",
        "    print(\"---------------------------------------\")\n",
        "    print(\"ttc\")\n",
        "    print(\"random\")\n",
        "    print(score_over_segment(df_llm_ttc, \"ground_truth\", \"random_label\", \"is_few_shot\", metric=metric))\n",
        "    print(\"model\")\n",
        "    print(score_over_segment(df_llm_ttc, \"ground_truth\", \"is_hateful\", \"is_few_shot\", metric=metric))\n",
        "    print(\"=======================================\")"
      ],
      "metadata": {
        "id": "V20jyCr_icEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# after flipping\n",
        "for metric in [\"acc\",\"ate\"]:\n",
        "    print(metric)\n",
        "    print(\"all result\")\n",
        "    print(\"random\")\n",
        "    print(score_over_segment(df_llm, \"ground_truth\", \"random_label\", \"few_shot_num\", metric=metric))\n",
        "    print(\"model\")\n",
        "    print(score_over_segment(df_llm, \"ground_truth\", \"is_hateful_ttc\", \"few_shot_num\", metric=metric))\n",
        "    print(\"---------------------------------------\")\n",
        "    print(\"ttc\")\n",
        "    print(\"random\")\n",
        "    print(score_over_segment(df_llm_ttc, \"ground_truth\", \"random_label\", \"few_shot_num\", metric=metric))\n",
        "    print(\"model\")\n",
        "    print(score_over_segment(df_llm_ttc, \"ground_truth\", \"is_hateful_ttc\", \"few_shot_num\", metric=metric))\n",
        "    print(\"=======================================\")"
      ],
      "metadata": {
        "id": "C2mv5b6Eim4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# after flipping - few_shot or not\n",
        "for metric in [\"acc\",\"ate\"]:\n",
        "    print(metric)\n",
        "    print(\"all result\")\n",
        "    print(\"random\")\n",
        "    print(score_over_segment(df_llm, \"ground_truth\", \"random_label\", \"is_few_shot\", metric=metric))\n",
        "    print(\"model\")\n",
        "    print(score_over_segment(df_llm, \"ground_truth\", \"is_hateful_ttc\", \"is_few_shot\", metric=metric))\n",
        "    print(\"---------------------------------------\")\n",
        "    print(\"ttc\")\n",
        "    print(\"random\")\n",
        "    print(score_over_segment(df_llm_ttc, \"ground_truth\", \"random_label\", \"is_few_shot\", metric=metric))\n",
        "    print(\"model\")\n",
        "    print(score_over_segment(df_llm_ttc, \"ground_truth\", \"is_hateful_ttc\", \"is_few_shot\", metric=metric))\n",
        "    print(\"=======================================\")"
      ],
      "metadata": {
        "id": "LGnTzz4xi9Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# after flipping - hateful+sarcastic\n",
        "for metric in [\"acc\",\"ate\"]:\n",
        "    print(metric)\n",
        "    print(\"all result\")\n",
        "    # print(\"random\")\n",
        "    # print(score_over_segment(df_llm, \"ground_truth\", \"random_label\", \"few_shot_num\", metric=metric))\n",
        "    print(\"model\")\n",
        "    print(score_over_segment(df_llm, \"ground_truth\", \"is_hateful_or_sarcastic_ttc\", \"few_shot_num\", metric=metric))\n",
        "    print(\"---------------------------------------\")\n",
        "    print(\"ttc\")\n",
        "    # print(\"random\")\n",
        "    # print(score_over_segment(df_llm_ttc, \"ground_truth\", \"random_label\", \"few_shot_num\", metric=metric))\n",
        "    print(\"model\")\n",
        "    print(score_over_segment(df_llm_ttc, \"ground_truth\", \"is_hateful_or_sarcastic_ttc\", \"few_shot_num\", metric=metric))\n",
        "    print(\"=======================================\")"
      ],
      "metadata": {
        "id": "me9jht55mpDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vilio"
      ],
      "metadata": {
        "id": "lvwcRzGABNVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### preprocessing"
      ],
      "metadata": {
        "id": "HhBBz9XSX0yp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### shared 1"
      ],
      "metadata": {
        "id": "HyVUBZTKwI-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# limit scope\n",
        "score_type=\"attattr\"\n",
        "# input_modality=\"txt\"\n",
        "# submodel=\"U72\"\n",
        "df_scope = df_vilio[\n",
        "    (df_vilio[\"score_type\"]==score_type)\n",
        "    # &(df_horizontal[\"input_modality\"]==input_modality)\n",
        "    # &(df_horizontal[\"submodel\"]==submodel)\n",
        "].drop(\"score_type\", axis=1).reset_index(drop=True)\n",
        "df_scope.head()"
      ],
      "metadata": {
        "id": "D3rsNK0TYCht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transpose\n",
        "for i,it in enumerate(df_scope[\"interaction_type\"].unique()):\n",
        "    df_it = df_scope.loc[df_scope[\"interaction_type\"]==it, KEEP_COLS].reset_index(drop=True).rename(plot_cols, axis=1)\n",
        "    if not i:\n",
        "        it_dict = {\"MIDAS\": f\"MIDAS_{it}\"}\n",
        "        df_horizontal = df_it.copy()\n",
        "    else:\n",
        "        df_it = df_it.set_index(KEY_COLS).drop(\"miATE\", axis=1)\n",
        "        df_horizontal = df_horizontal.merge(df_it, left_on=KEY_COLS, right_index=True, suffixes=[\"\", f\"_{it}\"])\n",
        "df_horizontal = df_horizontal.rename(it_dict, axis=1)\n",
        "df_horizontal.head()"
      ],
      "metadata": {
        "id": "Np00tFE58fiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target variable\n",
        "df_horizontal[f\"{plot_cols[PRED_COL]}_category\"] = (df_horizontal[plot_cols[PRED_COL]]>=0.5).astype(int)\n",
        "df_scope = df_horizontal.drop(plot_cols[PRED_COL], axis=1)\n",
        "df_scope.head()"
      ],
      "metadata": {
        "id": "zbGU8JQWckNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropna\n",
        "df_analysis = df_scope.dropna()\n",
        "print(f\"# samples [before,after] = {[len(df_scope),len(df_analysis)]}\")"
      ],
      "metadata": {
        "id": "xNBlgs52pvFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### for category-interaction"
      ],
      "metadata": {
        "id": "LX2UW64BwMVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dummies\n",
        "# df_dummies = pd.get_dummies(df_analysis[dummy_cols], drop_first=True)\n",
        "df_dummies = pd.get_dummies(df_analysis[dummy_cols])\n",
        "df_dummied = df_analysis.merge(df_dummies, left_index=True, right_index=True)\n",
        "assert len(df_analysis)==len(df_dummied), f\"# samples should match before/after processing: {len(df_analysis),len(df_dummied)}\"\n",
        "df_dummied.head()"
      ],
      "metadata": {
        "id": "nB-FK73hZvVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# interaction terms\n",
        "df_analysis = df_dummied.copy()\n",
        "score_cols = ['MIDAS_all', 'MIDAS_text', 'MIDAS_cross', 'MIDAS_image']\n",
        "# df_analysis = df_dummied.drop('MIDAS_all', axis=1)\n",
        "# score_cols = ['MIDAS_text', 'MIDAS_cross', 'MIDAS_image']\n",
        "category_cols = df_analysis.columns.tolist()\n",
        "for col in [\"id\",f\"{plot_cols[PRED_COL]}_category\"]+score_cols+dummy_cols:\n",
        "    category_cols.remove(col)\n",
        "for s_col in score_cols:\n",
        "    for c_col in category_cols:\n",
        "        df_analysis[f\"{s_col}_{c_col}\"] = df_analysis[s_col]*df_analysis[c_col]\n",
        "df_analysis.head()"
      ],
      "metadata": {
        "id": "gIulhioKheM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### shared 2"
      ],
      "metadata": {
        "id": "Elz27pMkwWBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for modeling\n",
        "df_analysis = df_analysis.drop(dummy_cols, axis=1)\n",
        "X_cols = df_analysis.columns.tolist()\n",
        "remove_cols = [\"id\",f\"{plot_cols[PRED_COL]}_category\"]\n",
        "for col in remove_cols:\n",
        "    X_cols.remove(col)\n",
        "df_train_eval, df_test = train_test_split(df_analysis, random_state=RS, test_size=0.3)\n",
        "df_train, df_eval = train_test_split(df_train_eval, random_state=RS, test_size=0.2)\n",
        "print(f\"[train, eval, test] size: {[df_train.shape, df_eval.shape, df_test.shape]}\")\n",
        "X_train_eval = df_train_eval[X_cols].values\n",
        "y_train_eval = df_train_eval[f\"{plot_cols[PRED_COL]}_category\"].values\n",
        "X_train, X_eval, X_test = df_train[X_cols].values, df_eval[X_cols].values, df_test[X_cols].values\n",
        "y_train = df_train[f\"{plot_cols[PRED_COL]}_category\"].values\n",
        "y_eval = df_eval[f\"{plot_cols[PRED_COL]}_category\"].values\n",
        "y_test = df_test[f\"{plot_cols[PRED_COL]}_category\"].values"
      ],
      "metadata": {
        "id": "zZUazS1GYQ9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### interaction modeling"
      ],
      "metadata": {
        "id": "-1fBe4KFRNK9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### for all"
      ],
      "metadata": {
        "id": "3JWe6Hg7Rf_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model class\n",
        "params = {\n",
        "    'verbose': -1,\n",
        "    'task': 'train',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'binary',\n",
        "    'metric': 'binary_logloss',\n",
        "    'learning_rate': 0.1,\n",
        "    'seed': RS,\n",
        "    'deterministic':True,\n",
        "    'force_row_wise':True\n",
        "}"
      ],
      "metadata": {
        "id": "D4u6quztgZEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit\n",
        "lgb_train = opt_lgb.Dataset(X_train, y_train)\n",
        "lgb_valid = opt_lgb.Dataset(X_eval, y_eval, reference=lgb_train)\n",
        "lgb_test = opt_lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
        "lgb_results = {}\n",
        "model = opt_lgb.LightGBMTuner(\n",
        "    params=params,\n",
        "    train_set=lgb_train,\n",
        "    valid_sets=[lgb_train, lgb_valid],\n",
        "    valid_names=['Train', 'Valid'],\n",
        "    num_boost_round=500,\n",
        "    early_stopping_rounds=5,\n",
        "    evals_result=lgb_results,\n",
        "    verbosity=-1,\n",
        "    verbose_eval=-1,\n",
        "    optuna_seed=RS,\n",
        ")\n",
        "model.run()\n",
        "model = model.get_best_booster()"
      ],
      "metadata": {
        "id": "YN92kpn-mPx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.params)"
      ],
      "metadata": {
        "id": "vEx0x2BSZJLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "preds = model.predict(X_test)\n",
        "fpr, tpr, _ = roc_curve(y_test,  preds)\n",
        "auc = roc_auc_score(y_test, preds)\n",
        "print(\"AUC=\"+str(auc))\n",
        "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QrbcFJdtmOQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance = pd.DataFrame({'feature': X_cols, 'importance': model.feature_importance()})\n",
        "types = ['MIDAS_text','MIDAS_cross','MIDAS_image','model_type_O','model_type_U','model_type_V']\n",
        "for t in types:\n",
        "    importance[f'is_{t}']= 0\n",
        "    importance.loc[importance['feature'].str.contains(t), f'is_{t}']= 1\n",
        "importance = importance[importance[\"importance\"]>=1].reset_index(drop=True)\n",
        "categories = [f\"is_{tp}\" for tp in types]\n",
        "imp_grp = importance.groupby(categories)\n",
        "imp_feat = imp_grp[\"feature\"].nunique().reset_index(drop=False)\n",
        "imp_sum = imp_grp[\"importance\"].sum().reset_index(drop=False)\n",
        "print(imp_feat)\n",
        "print(\"==================\")\n",
        "print(imp_sum)\n",
        "imp_feat.to_csv(f\"{DRIVE_DIR}/{VILIO_DIR}/{EXPORT_DIR}/all_optuna_nunique_{RS}.csv\", index=False)\n",
        "imp_sum.to_csv(f\"{DRIVE_DIR}/{VILIO_DIR}/{EXPORT_DIR}/all_optuna_occurrences_{RS}.csv\", index=False)"
      ],
      "metadata": {
        "id": "d40CvYdb-2LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### for each model type"
      ],
      "metadata": {
        "id": "QsfiKxn9RkJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aucs = {}\n",
        "df_test[\"preds\"] = model.predict(X_test)\n",
        "for tp in [\"O\",\"U\",\"V\"]:\n",
        "    print(f\"Model {tp}\")\n",
        "    if tp==\"O\":\n",
        "        df_plot_scope = df_test[(df_test[f\"model_type_U\"]==0)&(df_test[f\"model_type_V\"]==0)].reset_index(drop=True)\n",
        "    else:\n",
        "        df_plot_scope = df_test[df_test[f\"model_type_{tp}\"]==1].reset_index(drop=True)\n",
        "    fpr, tpr, _ = roc_curve(df_plot_scope[f\"{plot_cols[PRED_COL]}_category\"],  df_plot_scope[\"preds\"])\n",
        "    auc = roc_auc_score(df_plot_scope[f\"{plot_cols[PRED_COL]}_category\"],  df_plot_scope[\"preds\"])\n",
        "    print(\"AUC=\"+str(auc))\n",
        "    aucs[tp] = auc\n",
        "    plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.legend(loc=4)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Y0mLyYAhuHY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(aucs)"
      ],
      "metadata": {
        "id": "BbgqpTAb1nMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aucs2 = {}\n",
        "for tp in [\"O\",\"U\",\"V\"]:\n",
        "    print(f\"Model {tp}\")\n",
        "    params = {\n",
        "        'verbose': -1,\n",
        "        'task': 'train',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'objective': 'binary',\n",
        "        'metric': 'binary_logloss',\n",
        "        'learning_rate': 0.1,\n",
        "        'seed': RS,\n",
        "        'deterministic':True,\n",
        "        'force_row_wise':True\n",
        "    }\n",
        "    if tp==\"O\":\n",
        "        model_scope = (df_analysis[f\"model_type_U\"]==0)&(df_analysis[f\"model_type_V\"]==0)\n",
        "    else:\n",
        "        model_scope = df_analysis[f\"model_type_{tp}\"]==1\n",
        "    df_analysis_scope = df_analysis[model_scope].reset_index(drop=True)\n",
        "\n",
        "    df_train_eval, df_test = train_test_split(df_analysis_scope, random_state=RS, test_size=0.3)\n",
        "    df_train, df_eval = train_test_split(df_train_eval, random_state=RS, test_size=0.2)\n",
        "    print(f\"[train, eval, test] size: {[df_train.shape, df_eval.shape, df_test.shape]}\")\n",
        "    X_train_eval = df_train_eval[X_cols].values\n",
        "    y_train_eval = df_train_eval[f\"{plot_cols[PRED_COL]}_category\"].values\n",
        "    X_train, X_eval, X_test = df_train[X_cols].values, df_eval[X_cols].values, df_test[X_cols].values\n",
        "    y_train = df_train[f\"{plot_cols[PRED_COL]}_category\"].values\n",
        "    y_eval = df_eval[f\"{plot_cols[PRED_COL]}_category\"].values\n",
        "    y_test = df_test[f\"{plot_cols[PRED_COL]}_category\"].values\n",
        "\n",
        "    lgb_train = opt_lgb.Dataset(X_train, y_train)\n",
        "    lgb_valid = opt_lgb.Dataset(X_eval, y_eval, reference=lgb_train)\n",
        "    lgb_test = opt_lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
        "\n",
        "    lgb_results = {}\n",
        "    model = opt_lgb.LightGBMTuner(\n",
        "        params=params,\n",
        "        train_set=lgb_train,\n",
        "        valid_sets=[lgb_train, lgb_valid],\n",
        "        valid_names=['Train', 'Valid'],\n",
        "        num_boost_round=500,\n",
        "        early_stopping_rounds=5,\n",
        "        evals_result=lgb_results,\n",
        "        verbosity=-1,\n",
        "        verbose_eval=-1,\n",
        "        optuna_seed=RS,\n",
        "    )\n",
        "    model.run()\n",
        "    model = model.get_best_booster()\n",
        "    print(model.params)\n",
        "    print(\"------------------\")\n",
        "\n",
        "    preds = model.predict(X_test)\n",
        "    fpr, tpr, _ = roc_curve(y_test,  preds)\n",
        "    auc = roc_auc_score(y_test, preds)\n",
        "    print(\"AUC=\"+str(auc))\n",
        "    aucs2[tp] = auc\n",
        "    plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.legend(loc=4)\n",
        "    plt.show()\n",
        "    print(\"------------------\")\n",
        "\n",
        "    importance = pd.DataFrame({'feature': X_cols, 'importance': model.feature_importance()})\n",
        "    submodels = df_vilio[\"submodel\"].unique().tolist()\n",
        "    submodel_cols = [f\"submodel_{model}\" for model in submodels]\n",
        "    types = ['MIDAS_text','MIDAS_cross','MIDAS_image']+submodel_cols\n",
        "    for t in types:\n",
        "        importance[f'is_{t}']= 0\n",
        "        importance.loc[importance['feature'].str.contains(t), f'is_{t}']= 1\n",
        "    importance = importance[importance[\"importance\"]>=1].reset_index(drop=True)\n",
        "    categories = [f\"is_{tp}\" for tp in types]\n",
        "    imp_grp = importance.groupby(categories)\n",
        "    imp_feat = imp_grp[\"feature\"].nunique().reset_index(drop=False)\n",
        "    imp_sum = imp_grp[\"importance\"].sum().reset_index(drop=False)\n",
        "    print(imp_feat)\n",
        "    print(\"------------------\")\n",
        "    print(imp_sum)\n",
        "    print(\"==================\")\n",
        "    imp_feat.to_csv(f\"{DRIVE_DIR}/{VILIO_DIR}/{EXPORT_DIR}/{tp}_indv_optuna_nunique_{RS}.csv\", index=False)\n",
        "    imp_sum.to_csv(f\"{DRIVE_DIR}/{VILIO_DIR}/{EXPORT_DIR}/{tp}_indv_optuna_occurrences_{RS}.csv\", index=False)"
      ],
      "metadata": {
        "id": "_x6HZAyUv7Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(aucs2)"
      ],
      "metadata": {
        "id": "rZmLNN9u0wBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## export"
      ],
      "metadata": {
        "id": "cJpnFyXrLqxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = lgb_results2df()\n",
        "print(dfs.keys())\n",
        "for ky in dfs.keys():\n",
        "    print(ky)\n",
        "    print(dfs[ky].shape)"
      ],
      "metadata": {
        "id": "5_g2Jk2JLr-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_cols = dfs[\"_indv_optuna_occurrences_\"].drop(\"importance\", axis=1).columns.tolist()\n",
        "df_merged = dfs[\"_indv_optuna_nunique_\"].merge(dfs[\"_indv_optuna_occurrences_\"].set_index(key_cols), left_on=key_cols, right_index=True)\n",
        "df_merged.head()"
      ],
      "metadata": {
        "id": "GqZKVoZcEBzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged.to_csv(f\"{DRIVE_DIR}/{VILIO_DIR}/{EXPORT_DIR}/indv_optuna_merged.csv\", index=False)"
      ],
      "metadata": {
        "id": "chzOmXEhEBmQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}