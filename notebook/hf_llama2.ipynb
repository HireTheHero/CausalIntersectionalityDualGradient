{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSugUQTJZ3Eg"
      },
      "source": [
        "# prerequisite\n",
        "- [Register LLaMA / HuggingFace LLaMA](https://huggingface.co/blog/llama2)\n",
        "    - Add LLaMA access token to *DRIVE_PATH*/hf/token.txt\n",
        "- Place confouders.parquet under *DRIVE_PATH*/annotation\n",
        "- Run [image2text.py](https://github.com/HireTheHero/MemesModalityEvaluation/blob/main/script/blip2/image2text.py) to get BLIP2 captions and place under *DRIVE_PATH*/annotation\n",
        "- meta_result.csv should be placed under *DRIVE_PATH*/hf for reproducing meta learning analysis\n",
        "\n",
        "- All set!\n",
        "\n",
        "## reference\n",
        "- [LLaMAForCausalLM](https://huggingface.co/blog/how-to-generate)\n",
        "- [pipeline](https://huggingface.co/blog/llama2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER9pe4KEKdAo"
      },
      "source": [
        "# init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vho8RqgELg07"
      },
      "source": [
        "## google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqBcbCEALi7l"
      },
      "outputs": [],
      "source": [
        "# mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vb-Un-I3LmC7"
      },
      "outputs": [],
      "source": [
        "# variables\n",
        "# token_path = \"/content/drive/MyDrive/vilio/token.txt\"\n",
        "hf_token_path = \"/content/drive/MyDrive/hf/token.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2YJzCIRLqOJ"
      },
      "outputs": [],
      "source": [
        "class TokenNotLoadedException(Exception):\n",
        "    pass\n",
        "def load_token(path):\n",
        "    token = None\n",
        "    with open(path, \"r\") as f:\n",
        "        token = f.readline()\n",
        "    if token is not None:\n",
        "        print(\"Loaded.\\nNote that the verification for actual token is not implemented for security reason. You're on your own for that.\")\n",
        "    else:\n",
        "        raise TokenNotLoadedException(\"Check your token and/or path\")\n",
        "    return token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-K5TsZciWWW"
      },
      "outputs": [],
      "source": [
        "# token = load_token(token_path)\n",
        "hf_token = load_token(hf_token_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkCoy7sMKe54"
      },
      "source": [
        "## env setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCCKyygvpZMW"
      },
      "outputs": [],
      "source": [
        "%%writefile requirements.txt\n",
        "accelerate==0.21.0\n",
        "einops==0.6.0\n",
        "sentencepiece==0.1.99\n",
        "transformers==4.31.0\n",
        "xformers==0.0.20\n",
        "optuna==3.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xybDvD-LpnII"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1glLXZ5KZND"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login --token=$hf_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP5JclwWkh14"
      },
      "source": [
        "## github"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fedebotu/clone-anonymous-github\n",
        "!cd clone-anonymous-github; pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "x3K3Om1bSbL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8LOlF-Dw3s0"
      },
      "outputs": [],
      "source": [
        "# SCRIPT_ROOT = \"/content\"\n",
        "# URL = \"https://anonymous.4open.science/r/MemesModalityEvaluation-2540\"\n",
        "SCRIPT_PATH = \"/content/MemesModalityEvaluation-2540\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf $SCRIPT_PATH"
      ],
      "metadata": {
        "id": "MQv7wjpsZ-6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd clone-anonymous-github; python src/download.py \\\n",
        "    --url https://anonymous.4open.science/r/MemesModalityEvaluation-2540 \\\n",
        "    --save_dir /content"
      ],
      "metadata": {
        "id": "68d5SVRPZOPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z39JrskD22AY"
      },
      "outputs": [],
      "source": [
        "!cd $SCRIPT_PATH; bash shell/hf_overwrite_scripts.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZawL1DLlLG8Y"
      },
      "source": [
        "## modules and variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ra-dla_8KyqY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from transformers import AutoTokenizer, LlamaForCausalLM\n",
        "import transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h02fXgfvLEOB"
      },
      "outputs": [],
      "source": [
        "MDOEL = \"meta-llama/Llama-2-13b-chat-hf\"\n",
        "LARGE = \"meta-llama/Llama-2-70b-chat-hf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJNm1J4qrxzN"
      },
      "outputs": [],
      "source": [
        "DRIVE_PATH = \"/content/drive/MyDrive\"\n",
        "DATA_DIR = \"/content/hm\"\n",
        "PROMPT_DIR = \"/content/prompts\"\n",
        "RESULT_DIR = \"/content/results\"\n",
        "CONFIG_DIR = \"/content/MemesModalityEvaluation/script/llama/hf\"\n",
        "SAVE_DIR_FIN = f\"{DRIVE_PATH}/hf\"\n",
        "IMAGE_DIR = f\"{DATA_DIR}/hateful_memes/img\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ona9gSvijrLN"
      },
      "source": [
        "## load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N42b0fGLtExr"
      },
      "outputs": [],
      "source": [
        "!mkdir $DATA_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbe17VNvreHw"
      },
      "outputs": [],
      "source": [
        "# blip2 captions / confounders\n",
        "!cp $DRIVE_PATH/annotation/confounders.parquet $DATA_DIR\n",
        "!cp $DRIVE_PATH/annotation/hm_captions.parquet $DATA_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ascP3dcbjo2e"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# hateful memes from MyDrive\n",
        "!unzip $DRIVE_PATH/vilio/hateful_memes.zip -d $DATA_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD5LPIIBtitT"
      },
      "source": [
        "# run scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdg7tvVYtkiT"
      },
      "outputs": [],
      "source": [
        "# data preparation\n",
        "!rm -rf $PROMPT_DIR\n",
        "!mkdir $PROMPT_DIR\n",
        "!python $SCRIPT_PATH/script/llama/prompt_extraction.py \\\n",
        "    --caption_dir $DATA_DIR \\\n",
        "    --meme_dir $DATA_DIR/hateful_memes \\\n",
        "    --conf_dir $DATA_DIR \\\n",
        "    --save_dir $PROMPT_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wva3S44y28q"
      },
      "outputs": [],
      "source": [
        "# experiment\n",
        "!rm -rf $RESULT_DIR\n",
        "!mkdir $RESULT_DIR\n",
        "!python $SCRIPT_PATH/script/llama/hf/few_shot_generation.py \\\n",
        "    --save_path $RESULT_DIR \\\n",
        "    --prompts_path $PROMPT_DIR \\\n",
        "    --config_path $CONFIG_DIR \\\n",
        "    --max_seq_len 2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0jSi8UlxQ_N"
      },
      "outputs": [],
      "source": [
        "# collect result\n",
        "!python $SCRIPT_PATH/script/llama/hf/result_collection.py \\\n",
        "    --result_path $RESULT_DIR \\\n",
        "    --prompt_path $PROMPT_DIR \\\n",
        "    --save_path $SAVE_DIR_FIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6KnLkxchVx0"
      },
      "outputs": [],
      "source": [
        "# meta-learning analysis\n",
        "!rm -rf $SAVE_DIR_FIN/atts\n",
        "!mkdir $SAVE_DIR_FIN/atts\n",
        "!python $SCRIPT_PATH/script/llama/hf/meta_gradient.py \\\n",
        "    --result_path $RESULT_DIR \\\n",
        "    --prompt_path $PROMPT_DIR \\\n",
        "    --save_path $SAVE_DIR_FIN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBlrHjIo4lG_"
      },
      "source": [
        "# evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeyjsIrN4m5p"
      },
      "source": [
        "## check content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye1ex4nFMpmX"
      },
      "outputs": [],
      "source": [
        "df_result = pd.read_csv(f\"{SAVE_DIR_FIN}/extracted_info.csv\").sort_values(by=[\"image_id\", \"few_shot_num\"], ascending=True).reset_index(drop=True)\n",
        "df_result.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eByE-aSWNrti"
      },
      "outputs": [],
      "source": [
        "print(len(df_result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WG9Hg67jCTOs"
      },
      "outputs": [],
      "source": [
        "image_id=\"07653\"\n",
        "image_ids = df_result[\"image_id\"].apply(lambda x: x.split(\"_\")[0])\n",
        "df_img = df_result[image_ids==image_id].copy()\n",
        "image_info = df_img[\"image_id\"].values[0]\n",
        "print(image_info)\n",
        "im = Image.open(f\"{IMAGE_DIR}/{image_id}.png\")\n",
        "print(df_result[\"prompt\"].values[0])\n",
        "print(\"=======================\")\n",
        "print(df_result[\"extracted_info\"].values[0])\n",
        "print(\"=======================\")\n",
        "display(im)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwCikodV4sZD"
      },
      "source": [
        "# annotation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ujlyE4-DbFx"
      },
      "source": [
        "## init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8pqnh7wDfY1"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import time\n",
        "\n",
        "# from IPython.display import clear_output\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "em5ytprGDyht"
      },
      "outputs": [],
      "source": [
        "DRIVE_PATH = \"/content/drive/MyDrive\"\n",
        "SAVE_DIR_FIN = f\"{DRIVE_PATH}/hf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I5ySrVZDcxk"
      },
      "source": [
        "## annotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Va6sbQ4lnp3"
      },
      "outputs": [],
      "source": [
        "# version,version_next=\"v2_10\",\"v2_11\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4dke_CBO9Ga"
      },
      "outputs": [],
      "source": [
        "# df_result = pd.read_csv(f\"{SAVE_DIR_FIN}/extracted_info.csv\").sort_values(by=[\"image_id\", \"few_shot_num\"], ascending=True).reset_index(drop=True)\n",
        "# df_result.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fidVER9DvXLA"
      },
      "outputs": [],
      "source": [
        "# n_samples = len(df_result)\n",
        "# out_name = f\"{SAVE_DIR_FIN}/df_meta_{version}.csv\"\n",
        "# cols = [\"image_id\", \"few_shot_num\", \"ans_num\", \"is_functional\", \"is_formatted\", \"is_hateful\", \"is_sarcastic\", \"is_benign\", \"ground_truth\", \"image_info\", \"prompt\", \"extracted_info\", \"generated_text\"]\n",
        "# if os.path.isfile(out_name):\n",
        "#     df_labeled = pd.read_csv(out_name)[cols]\n",
        "#     is_first = 0\n",
        "#     label_dict = df_labeled.to_dict(\"list\")\n",
        "#     completed = (df_labeled[\"image_id\"].astype(str).str.zfill(5)+\"_\"+df_labeled[\"few_shot_num\"].astype(str)).tolist()\n",
        "# else:\n",
        "#     is_first = 1\n",
        "#     label_dict = {col: [] for col in cols}\n",
        "#     processed_id_shots = []\n",
        "# # for idx in range(n_samples):\n",
        "# for idx in range(n_samples):\n",
        "#     # metadata extraction\n",
        "#     image_info = df_result[\"image_id\"].values[idx]\n",
        "#     few_shot_num = df_result[\"few_shot_num\"].values[idx]\n",
        "#     image_id = image_info.split(\"_\")[0]\n",
        "#     if not is_first and f\"{image_id}_{few_shot_num}\" in completed:\n",
        "#         continue\n",
        "#     print(f\"Image id with info {image_info} shot #{few_shot_num}: Sample #{idx} out of {n_samples}\")\n",
        "#     pos_idx = image_info.split(\"_pos_\")[0].split(\"_\")[1:]\n",
        "#     max_idx = image_info.split(\"_max_\")[-1]\n",
        "#     # text extraction\n",
        "#     prompt = df_result[\"prompt\"].values[idx].replace(\"\\n\\n\\n\", \"\")\n",
        "#     extracted = df_result[\"extracted_info\"].values[idx].replace(\"\\n\\n\\n\", \"\")\n",
        "#     generated = df_result[\"generated_text\"].values[idx].replace(\"\\n\\n\\n\", \"\")\n",
        "#     print(f\"Prompt: \\n{prompt}\")\n",
        "#     print(\"===========================\")\n",
        "#     print(f\"Extracted: \\n{extracted}\")\n",
        "#     print(\"===========================\")\n",
        "#     is_functional = int(input(\"Is properly answered?: \"))\n",
        "#     if is_functional:\n",
        "#         is_formatted = int(input(\"Is formatted like 'Most likely xx sample is...'?: \"))\n",
        "#     for idx2 in range(int(max_idx)+1):\n",
        "#         print([idx2, pos_idx, str(idx2) in pos_idx])\n",
        "#         print(f\"Image-caption pair #{idx2}\")\n",
        "#         # basic info\n",
        "#         label_dict[\"image_id\"].append(image_id)\n",
        "#         label_dict[\"few_shot_num\"].append(few_shot_num)\n",
        "#         label_dict[\"ans_num\"].append(idx2)\n",
        "#         label_dict[\"image_info\"].append(image_info)\n",
        "#         label_dict[\"prompt\"].append(prompt)\n",
        "#         label_dict[\"extracted_info\"].append(extracted)\n",
        "#         label_dict[\"generated_text\"].append(generated)\n",
        "#         # label detection\n",
        "#         if str(idx2) in pos_idx:\n",
        "#             label_dict[\"ground_truth\"].append(1)\n",
        "#             print(\"Ground-truth label should be hateful\")\n",
        "#         else:\n",
        "#             label_dict[\"ground_truth\"].append(0)\n",
        "#             print(\"Ground-truth label should be benign\")\n",
        "#         # annotation\n",
        "#         if not is_functional:\n",
        "#             # auto-label 0\n",
        "#             label_dict[\"is_functional\"].append(0)\n",
        "#             label_dict[\"is_formatted\"].append(0)\n",
        "#             label_dict[\"is_hateful\"].append(0)\n",
        "#             label_dict[\"is_sarcastic\"].append(0)\n",
        "#             label_dict[\"is_benign\"].append(0)\n",
        "#         else:\n",
        "#             # manual annotation\n",
        "#             is_hateful = int(input(\"Is labeled hateful?: \"))\n",
        "#             if not is_hateful:\n",
        "#                 is_sarcastic = int(input(\"Is labeled sarcastic?: \"))\n",
        "#             else:\n",
        "#                 is_sarcastic = 0\n",
        "#             label_dict[\"is_functional\"].append(is_functional)\n",
        "#             label_dict[\"is_formatted\"].append(is_formatted)\n",
        "#             label_dict[\"is_hateful\"].append(is_hateful)\n",
        "#             label_dict[\"is_sarcastic\"].append(is_sarcastic)\n",
        "#             label_dict[\"is_benign\"].append(int(not (is_hateful or is_sarcastic)))\n",
        "#     time.sleep(5)\n",
        "#     clear_output(True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8ezDnXRQOGn"
      },
      "outputs": [],
      "source": [
        "# df_labeled = pd.DataFrame(label_dict)\n",
        "# df_labeled[\"image_id\"] = df_labeled[\"image_id\"].astype(str).str.zfill(5)\n",
        "# df_labeled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z35upuJJforg"
      },
      "outputs": [],
      "source": [
        "# out_name = f\"{SAVE_DIR_FIN}/df_meta_{version_next}.csv\"\n",
        "# df_labeled = pd.DataFrame(label_dict)\n",
        "# df_labeled.to_csv(out_name, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo8mderF2Jxo"
      },
      "source": [
        "# explain by attention weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N3njyz98t7D"
      },
      "source": [
        "## init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9QCBamV87uf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import optuna.integration.lightgbm as opt_lgb\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aXROhWq8_Bn"
      },
      "outputs": [],
      "source": [
        "DRIVE_PATH = \"/content/drive/MyDrive\"\n",
        "SAVE_DIR_FIN = f\"{DRIVE_PATH}/hf\"\n",
        "ATTS_PATH = f\"{SAVE_DIR_FIN}/atts\"\n",
        "# version = \"v2_11\"\n",
        "# out_name = f\"{SAVE_DIR_FIN}/df_meta_{version}.csv\"\n",
        "out_name = f\"{SAVE_DIR_FIN}/meta_result.csv\"\n",
        "gt_cols = ['is_functional', 'is_formatted', 'ground_truth']\n",
        "RS = 1991"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaKhyT_R8k6p"
      },
      "source": [
        "## data prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qumrXGHOgFRZ"
      },
      "outputs": [],
      "source": [
        "df_labeled = pd.read_csv(out_name)\n",
        "df_labeled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mn5bewoEf8KZ"
      },
      "outputs": [],
      "source": [
        "df_labeled[\"is_hateful_or_sarcastic\"] = (np.logical_or(df_labeled[\"is_hateful\"], df_labeled[\"is_sarcastic\"])).astype(int)\n",
        "df_labeled[\"is_few_shot\"] = 0\n",
        "df_labeled.loc[df_labeled[\"few_shot_num\"] != 0, \"is_few_shot\"] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPr2PPiPLSqE"
      },
      "outputs": [],
      "source": [
        "df_scope = df_labeled[df_labeled[\"few_shot_num\"].isin(range(3))].reset_index(drop=False)\n",
        "print(len(df_scope))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75keTqDB2S_-"
      },
      "outputs": [],
      "source": [
        "def preprocess_att(att_file, modality, mx_dim):\n",
        "    att = torch.load(att_file)\n",
        "    att_filled = F.pad(\n",
        "        input=att,\n",
        "        pad=(0,mx_dim[modality]-len(att)),\n",
        "        mode='constant', value=0\n",
        "    )\n",
        "    return att_filled\n",
        "\n",
        "def load_attentions(df,\n",
        "                    atts_path = ATTS_PATH,\n",
        "                    mx_dim = {\"caption\": 100, \"image\": 172, \"cross\": 212},\n",
        "                    mx_shots = 2,\n",
        "                    modalities = [\"caption\", \"image\", \"cross\"]):\n",
        "    image_infos = df['image_info'].values\n",
        "    att_samples = []\n",
        "    for image_info in image_infos:\n",
        "        att_sample = []\n",
        "        image_dir = f\"{atts_path}/{image_info}\"\n",
        "        assert os.path.isdir(image_dir)\n",
        "        for modality in modalities:\n",
        "            zsl_file = f\"{image_dir}/{modality}_zsl.pt\"\n",
        "            att_zsl_filled = preprocess_att(zsl_file, modality, mx_dim)\n",
        "            att_sample.append(att_zsl_filled)\n",
        "            for shot in range(mx_shots-1):\n",
        "                shot_file = f\"{image_dir}/{modality}_delta_{shot+1}.pt\"\n",
        "                att_shot_filled = preprocess_att(shot_file, modality, mx_dim)\n",
        "                att_sample.append(att_shot_filled)\n",
        "        att_sample = torch.cat(att_sample)\n",
        "        att_samples.append(att_sample)\n",
        "    out = torch.stack(att_samples)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col = gt_cols[0]\n",
        "print(col)"
      ],
      "metadata": {
        "id": "cAUINtVyT6LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWEcJZwnJ-KY"
      },
      "outputs": [],
      "source": [
        "atts = load_attentions(df_scope)\n",
        "atts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zNCqHLvPOzt"
      },
      "outputs": [],
      "source": [
        "atts_arr = atts.numpy()\n",
        "print(atts_arr.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df_scope[col].to_numpy()"
      ],
      "metadata": {
        "id": "BYmxM8A9UMUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsbIb9XSSZx0"
      },
      "outputs": [],
      "source": [
        "X_train_eval, X_test, y_train_eval, y_test = train_test_split(atts_arr, y, random_state=RS, test_size=0.3)\n",
        "X_train, X_eval, y_train, y_eval = train_test_split(X_train_eval, y_train_eval, random_state=RS, test_size=0.2)\n",
        "print(y_train.shape, y_eval.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbwMzRBV8m4D"
      },
      "source": [
        "## classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'verbose': -1,\n",
        "    'task': 'train',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'binary',\n",
        "    'metric': 'binary_logloss',\n",
        "    'learning_rate': 0.1,\n",
        "    'seed': RS,\n",
        "    'deterministic':True,\n",
        "    'force_row_wise':True\n",
        "}"
      ],
      "metadata": {
        "id": "_MM8fFskYtt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_train = opt_lgb.Dataset(X_train, y_train)\n",
        "lgb_valid = opt_lgb.Dataset(X_eval, y_eval, reference=lgb_train)\n",
        "lgb_test = opt_lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
        "lgb_result = {}\n",
        "model = opt_lgb.LightGBMTuner(\n",
        "    params=params,\n",
        "    train_set=lgb_train,\n",
        "    valid_sets=[lgb_train, lgb_valid],\n",
        "    valid_names=['Train', 'Valid'],\n",
        "    num_boost_round=500,\n",
        "    early_stopping_rounds=5,\n",
        "    evals_result=lgb_result,\n",
        "    verbosity=-1,\n",
        "    verbose_eval=-1,\n",
        "    optuna_seed=RS,\n",
        ")"
      ],
      "metadata": {
        "id": "s8U5Ng7-d2I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.run()\n",
        "print(model.get_best_booster().params)"
      ],
      "metadata": {
        "id": "AFPzL0n6eL4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvuSnC5gmcjV"
      },
      "source": [
        "## performance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba = model.get_best_booster().predict(X_test)\n",
        "fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(\"AUC=\"+str(auc))\n",
        "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XjAenVsEftvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzBx-F108pX3"
      },
      "source": [
        "## feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRhJFGNbZstz"
      },
      "outputs": [],
      "source": [
        "def generate_feature_names(\n",
        "    modalities = [\"caption\", \"image\", \"cross\"],\n",
        "    mx_dim = {\"caption\": 100, \"image\": 172, \"cross\": 212},\n",
        "    mx_shots = 2,\n",
        "    ):\n",
        "    out = []\n",
        "    for modality in modalities:\n",
        "        dim = mx_dim[modality]\n",
        "        for i_dim in range(dim):\n",
        "            out.append(f\"{modality}_zsl_{i_dim}\")\n",
        "        for shot in range(mx_shots-1):\n",
        "            for i_dim in range(dim):\n",
        "               out.append(f\"{modality}_delta_{shot+1}_{i_dim}\")\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = generate_feature_names()\n",
        "importance = pd.DataFrame({'feature': feature_names, 'importance': model.get_best_booster().feature_importance()})\n",
        "types = ['zsl', 'caption','cross','image']\n",
        "for t in types:\n",
        "    importance[f'is_{t}']= 0\n",
        "    importance.loc[importance['feature'].str.contains(t), f'is_{t}']= 1\n",
        "\n",
        "importance.to_csv(f\"{SAVE_DIR_FIN}/{col}_optuna_importance_{RS}.csv\", index=False)\n",
        "importance.sort_values(by=\"importance\", ascending=False).head()"
      ],
      "metadata": {
        "id": "VASBpY3Thf_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importance = pd.read_csv(f\"{SAVE_DIR_FIN}/{col}_optuna_importance_{RS}.csv\")\n",
        "importance = importance[importance[\"importance\"]>=1].reset_index(drop=True)\n",
        "categories = ['is_zsl', 'is_caption', 'is_cross', 'is_image']\n",
        "imp_grp = importance.groupby(categories)\n",
        "imp_feat = imp_grp[\"feature\"].nunique().reset_index(drop=False)\n",
        "imp_sum = imp_grp[\"importance\"].sum().reset_index(drop=False)\n",
        "print(imp_feat)\n",
        "print(imp_sum)\n",
        "imp_feat.to_csv(f\"{SAVE_DIR_FIN}/{col}_optuna_nunique_{RS}.csv\", index=False)\n",
        "imp_sum.to_csv(f\"{SAVE_DIR_FIN}/{col}_optuna_occurrences_{RS}.csv\", index=False)"
      ],
      "metadata": {
        "id": "H3xaiSj9iJ-7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}